{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### A simple app\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "### Test your app\n",
    "Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a45ceb18a1044218b47785ce0eb7a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value={}, description='Upload'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")# YOUR CODE HERE)\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.data[-1])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1032383cc3e849b4b7b1aa327a667b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value={}, description='Upload'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")# YOUR CODE HERE)\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.data[-1])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf27d18ecd74b82ad71cdc6f0930ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value={}, description='Upload'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")# YOUR CODE HERE)\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.data[-1])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5b1a82dfee4411bf702762ef2fa233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value={}, description='Upload'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")# YOUR CODE HERE)\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.data[-1])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting voila\n",
      "  Downloading voila-0.4.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-server<3,>=2.3.0\n",
      "  Downloading jupyterlab_server-2.16.5-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-client<=7.4.1,>=6.1.3\n",
      "  Downloading jupyter_client-7.4.1-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 51.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websockets>=9.0\n",
      "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 39.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core>=4.11.0\n",
      "  Downloading jupyter_core-4.12.0-py3-none-any.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting traitlets<6,>=5.0.3\n",
      "  Downloading traitlets-5.8.0-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 47.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert<8,>=6.4.5\n",
      "  Downloading nbconvert-7.2.7-py3-none-any.whl (273 kB)\n",
      "\u001b[K     |████████████████████████████████| 273 kB 49.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbclient<0.8,>=0.4.0\n",
      "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 549 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-server<2.0.0,>=1.18\n",
      "  Downloading jupyter_server-1.23.4-py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 41.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.28\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 2.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.8.3; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server<3,>=2.3.0->voila) (3.2.0)\n",
      "Collecting babel>=2.10\n",
      "  Downloading Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2>=3.0.3\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from jupyterlab-server<3,>=2.3.0->voila) (0.9.0)\n",
      "Collecting packaging>=21.3\n",
      "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tornado>=6.2\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 34.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 44.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq>=23.0\n",
      "  Downloading pyzmq-24.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 33.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nest-asyncio>=1.5.4\n",
      "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client<=7.4.1,>=6.1.3->voila) (0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from nbconvert<8,>=6.4.5->voila) (4.10.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert<8,>=6.4.5->voila) (2.5.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert<8,>=6.4.5->voila) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert<8,>=6.4.5->voila) (3.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert<8,>=6.4.5->voila) (1.4.2)\n",
      "Collecting mistune<3,>=2.0.3\n",
      "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
      "Collecting nbformat>=5.1\n",
      "  Downloading nbformat-5.7.1-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting markupsafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from jupyter-server<2.0.0,>=1.18->voila) (0.8.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from jupyter-server<2.0.0,>=1.18->voila) (0.7.1)\n",
      "Collecting anyio<4,>=3.1.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting argon2-cffi\n",
      "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.7/site-packages (from jupyter-server<2.0.0,>=1.18->voila) (1.5.0)\n",
      "Collecting websocket-client\n",
      "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.3.0->voila) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.3.0->voila) (2.9)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.28->jupyterlab-server<3,>=2.3.0->voila) (1.25.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.3; python_version < \"3.10\"->jupyterlab-server<3,>=2.3.0->voila) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.3; python_version < \"3.10\"->jupyterlab-server<3,>=2.3.0->voila) (3.7.4.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (45.2.0.post20200209)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->jupyterlab-server<3,>=2.3.0->voila) (19.3.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /opt/conda/lib/python3.7/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.3.0->voila) (2019.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->nbconvert<8,>=6.4.5->voila) (2.3.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert<8,>=6.4.5->voila) (0.5.1)\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<2.0.0,>=1.18->voila) (1.13.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<2.0.0,>=1.18->voila) (2.19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: jupyterlab 1.0.9 has requirement jupyterlab_server~=1.0.0, but you'll have jupyterlab-server 2.16.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: charset-normalizer, requests, importlib-metadata, babel, packaging, traitlets, jupyter-core, fastjsonschema, nbformat, tornado, python-dateutil, pyzmq, nest-asyncio, jupyter-client, nbclient, mistune, markupsafe, jinja2, tinycss2, jupyterlab-pygments, nbconvert, sniffio, anyio, argon2-cffi-bindings, argon2-cffi, websocket-client, jupyter-server, jupyterlab-server, websockets, voila\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script pybabel is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script jupyter-trust is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts jupyter-kernel, jupyter-kernelspec and jupyter-run are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script jupyter-execute is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts jupyter-dejavu and jupyter-nbconvert are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script wsdump is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script jupyter-server is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script voila is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 babel-2.11.0 charset-normalizer-2.1.1 fastjsonschema-2.16.2 importlib-metadata-5.2.0 jinja2-3.1.2 jupyter-client-7.4.1 jupyter-core-4.12.0 jupyter-server-1.23.4 jupyterlab-pygments-0.2.2 jupyterlab-server-2.16.5 markupsafe-2.1.1 mistune-2.0.4 nbclient-0.7.2 nbconvert-7.2.7 nbformat-5.7.1 nest-asyncio-1.5.6 packaging-22.0 python-dateutil-2.8.2 pyzmq-24.0.1 requests-2.28.1 sniffio-1.3.0 tinycss2-1.2.1 tornado-6.2 traitlets-5.8.0 voila-0.4.0 websocket-client-1.4.2 websockets-10.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: voila: not found\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Standalone app or web app\n",
    "\n",
    "You can run this notebook as a standalone app on your computer by following these steps:\n",
    "\n",
    "1. Download this notebook in a directory on your machine\n",
    "2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n",
    "3. Install voila if you don't have it already (``pip install voila``)\n",
    "4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n",
    "5. Customize your notebook to make your app prettier and rerun voila\n",
    "\n",
    "You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  I could not access the  \"checkpoints/\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your submission archive\n",
    "\n",
    "Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing: jupyter nbconvert --to html app.ipynb\n",
      "[NbConvertApp] Converting notebook app.ipynb to html\n",
      "[NbConvertApp] Writing 333204 bytes to app.html\n",
      "executing: jupyter nbconvert --to html cnn_from_scratch.ipynb\n",
      "[NbConvertApp] Converting notebook cnn_from_scratch.ipynb to html\n",
      "[NbConvertApp] Writing 1154246 bytes to cnn_from_scratch.html\n",
      "executing: jupyter nbconvert --to html transfer_learning.ipynb\n",
      "[NbConvertApp] Converting notebook transfer_learning.ipynb to html\n",
      "[NbConvertApp] Writing 407750 bytes to transfer_learning.html\n",
      "executing: jupyter nbconvert --to html Untitled.ipynb\n",
      "[NbConvertApp] Converting notebook Untitled.ipynb to html\n",
      "[NbConvertApp] Writing 272312 bytes to Untitled.html\n",
      "Adding files to submission_2022-12-23T07h44m.tar.gz\n",
      "src/model.py\n",
      "src/data.py\n",
      "src/optimization.py\n",
      "src/helpers.py\n",
      "src/__init__.py\n",
      "src/train.py\n",
      "src/create_submit_pkg.py\n",
      "src/transfer.py\n",
      "src/predictor.py\n",
      "app.ipynb\n",
      "cnn_from_scratch.ipynb\n",
      "transfer_learning.ipynb\n",
      "Untitled.ipynb\n",
      "cnn_from_scratch.html\n",
      "app.html\n",
      "Untitled.html\n",
      "transfer_learning.html\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Done. Please submit the file submission_2022-12-23T07h44m.tar.gz\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
